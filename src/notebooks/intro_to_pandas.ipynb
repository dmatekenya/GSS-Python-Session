{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling in Python\n",
    "-----\n",
    "In this tutorial, you will learn how to handle data in Python using common packages of Pandas and Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Outomes\n",
    "After going through this notebook, the leaner should:\n",
    "- Be familiar with  the following common operations in Pandas:\n",
    "    - Creating DataFrames\n",
    "    - Subsetting data\n",
    "    - Applying a function to a DataFrame\n",
    "    - Grouping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "Pandas is a library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series. Pandas is free software released under the three-clause BSD license. We will cover the following about pandas:\n",
    "- **Data structures**. We will focus on the pandas Dataframe which is the main data structuee often used when dealing with data. We will also cover pandas syntax for selecting columns, rows and others.\n",
    "- **Data exploration**. The different ways to explore a dataframe through summarization, sneaking peaking and others.\n",
    "- **Data Manipulation**. We cover things like how to create new columns/variables from existing variables with use of apply function. How to loop through dataframes.\n",
    "- **Grouping data**. How to perfom grouping and what kind of summary functions can you apply.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Data Structures in Pandas\n",
    "Pandas has two mainndata structures as follows: Series and DataFrames.\n",
    "1. **Series:** A 1-dimensional labelled array that can hold data of any type (integer, string, float, python objects, etc.). Itâ€™s axis labels are collectively called an index. An example of a Series object is one column from a DataFrame.\n",
    "2. **DataFrame:** A 2-dimensional labelled data structure with columns and both a row and a column index. A dataframe can be used to represent 3-D data using multiindexing. A DataFrame has the look of tabular data like in a spreadsheet or in R DataFrames or in statistical packages such as SPSS or STATA. The different columns of a DataFrame can have different data types. A dataframe is often abbreviated as ```df```.\n",
    "\n",
    "Please refer to the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html#user-guide) for user guide and API reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['Dunstan','Mercy','Khama','Lara','Khali','Gloria']\n",
    "names = pd.Series(data)\n",
    "print (names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a series using a dict object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"name\":['Dunstan','Mercy','Khama','Lara','Khali','Gloria']}\n",
    "names = pd.Series(data)\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "#### How to create a DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a dictionary**\n",
    "\n",
    "Thus, we are specifying values for each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"name\":['Dunstan','Mercy','Khama','Lara','Khali','Gloria'],\n",
    "       \"age\": [100, 20, 7, 11, 30, 88]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a list**\n",
    "\n",
    "Thus, we are specifying values for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( [[4, 7, 10], [5, 8, 11],\n",
    "          [6, 9, 12]],\n",
    "         columns=['a', 'b', 'c'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ingest external data**\n",
    "\n",
    "Pandas can work with many data stores and file formats. To take a quick look at what file formats pandas can read, type ```pd.read``` and then hit tab, you should see a list of all the file formats supported by pandas. In this example, we show how to load a CSV file into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pandas package\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Set the name of the CSV file\n",
    "data_file = \"../../data/power-outages.csv\"\n",
    "\n",
    "# Read data into dataframe\n",
    "# dataframe is the pandas object for handling tabular data\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Attributes of a DataFrame Object\n",
    "Just like any Python object, the pandas DataFrame has attributes, methods and functions. For now, lets focus on the attributes.\n",
    "Some of the DataFrame attributes can be used to explore the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-1**: Pandas DataFrame Attributes\n",
    "\n",
    "Refer to this [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#attributes-and-underlying-data) for details of available attributes for the Pandas DataFrame object.\n",
    "\n",
    "Find the following attributes of the DataFrame created above\n",
    "1. Datatype of the ```psu`` column\n",
    "2. Column names\n",
    "3. Number of observations in the dataset\n",
    "4. In your opinoin, what's the most useful DataFrame attribute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Syntax notes\n",
    "- **Uses object oriented syntax**. For instance, use ```dot``` syntax to refer to methods, attributes and functions. For functions, include round brackets. For example, ```df.shape``` returns the shape attribute value. On the other hand, ```df.sum()``` calls the sum() function.\n",
    "- **Column indexing/selection**.With a column name, you can select/index a column using ```dot``` syntax or square brackets.  For instance, if I would like to get the sum() of one column named **A**, \n",
    "I can either do ```df[\"A\"].sum()``` or ```df.A.sum()```. They are numerous caveats for this as we will see later.\n",
    "- **Indexing (selection) uses square brackets**. In general, selection of elements in any dimension of the DataFrame uses special operators (e.g, ```head, at, loc,```), square brackets and a numeric number or index inside the brackets. For instance, in the DataFrame we created above, which has a default index of ```RangeIndex (0, number of rows)```, we can make the following selection ```df.loc[10:15,['psu', 'lon', 'lat']]```. Note that they are several indexing options to get to the same result.\n",
    "- **Indexing with conditions**. We will see more in subsetting data, but if you would to select a column as well as select values which satisfy some condition. For instance, ```df[df[\"A\"] == 'k' ]``` would return a subset of the DataFrame where the condition is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterations\n",
    "Although you can getaway with generic Python for loops, Pandas DataFrames has special syntax for iterating over DataFrame rows. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print('Index: {}, PSU->{}'.format(index, row['psu']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-2: Indexing**\n",
    "In the power outages DataFrame above, do the following:\n",
    "1. Create a subset of the data where the ```psu = 35```\n",
    "2. Use the ```reset_index()``` with option ```inplace=True``` to reset the index\n",
    "3. Whats the power_state of observation at 228"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data\n",
    "Once you have read the data, pandas has many functions to allow you explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick exploration using some of the DataFrame attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the n-top rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datatypes and other info about the columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics if it makes sense\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Summarizing data**\n",
    "Pandas DataFrame offers several functions to report summary statistics from the whole DataFrame or \n",
    "you can do that for each column separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subsetting data**\n",
    "\n",
    "You may need to do this for several reasons such as to simply reduce the size of the dataset and to select only a few required variables.\n",
    "1. Subsetting observations by selecting rows. Available options include random sampling, selecting specific rows (e.g., first 1000), selecting rows which meet a specific logical condition based on colum **X**\n",
    "2. Subsetting columns. Simply select columns of interest. For instance, if available columns are ```A, B, C, D```, you can simply create a new DataFrame with columns **A and B** like so. ```df2 == df1[['A', 'B']]```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-3: Summary Statistics and Subsetting Data**\n",
    "\n",
    "1. Load the elevation dataset\n",
    "2. Whats the average elevation?\n",
    "3. Create a new dataframe with 'district' and 'elevation' only. Also, only keep districts where elevation is greater than the average.\n",
    "4. For this part, use the power_outages dataset, what proportion of the observations represent cases with no power (power_state = 0). Hint, use the ```value_counts()``` function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation\n",
    "How to do things like:\n",
    "- Create new columns\n",
    "- Rename columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_as_high_elevation(x, avg_elev):\n",
    "    if x > avg_elev:\n",
    "        return 'Yes'\n",
    "    \n",
    "    return 'No'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding new columns to DataFrame\n",
    "There are many ways to do this but here we show by applying a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_elev = df_elev.elev_metres.mean()\n",
    "df_elev['HighElev'] = df_elev.apply(lambda x: label_as_high_elevation(x['elev_metres'], avg_elev), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping data \n",
    "The syntax for grouping data is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='../../docs/groubBy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets consider the elevation dataset, what if we wanted to find out which state has the highest average elevation?** \n",
    "\n",
    "We would follow the following straight foward reasoning\n",
    "1. Group by state\n",
    "2. Find average elevation in each state\n",
    "3. Find maximum among the averages\n",
    "\n",
    "Lets see how to achieve this with pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do things look by state\n",
    "df_elev.state_region.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mode(x):\n",
    "    return x.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elev.HighElev.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_elev_groups = df_elev.groupby('state_region').agg({'elev_metres': 'mean'})\n",
    "#df_elev_groups = df_elev.groupby('state_region')['elev_metres'].mean()\n",
    "# df_elev_groups = df_elev.groupby('state_region')['elev_metres'].mean().reset_index(name ='AvgElev')\n",
    "# apply a function which isnt available in pandas agg function list\n",
    "summ_func = {'elev_metres': 'mean', 'longitude': 'first', 'latitude': 'first', 'HighElev': lambda x: x.mode()}\n",
    "df_elev_groups = df_elev.groupby('state_region').agg(summ_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can remove the unwanted colums\n",
    "df_elev_groups = df_elev.groupby('state_region').agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elev.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-4: Grouping data**\n",
    "We will use the power outages dataset for this exercise.\n",
    "\n",
    "1. Add a date column by using this function: ```datetime.strptime(date_str,  date_format).date()``` where date string is the column with date data and date format is ```'%m/%d/%y %H:%M'```. Please use apply as demonstrated before.\n",
    "2. Group data by PSU and date using the group by function. In this case, it will look something like this ```df.groupby(['A', 'B'])``` so that the two column names are in a list. Report the mean power state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps with Pandas\n",
    "Please refer to pandas [documentation](http://pandas.pydata.org/pandas-docs/stable/10min.html) for tutorials on how to perfom various tasks such as indexing rows, subsetting the data, chaning column names and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "**Numpy** is one of the underlying libraries which powers many high level packages such as pandas. In most case, you will not need to interact with **Numpy** directly but its an essential package for data manipulation and scientific computing in Python. Its useful for linear algebra, Fourier transform, and random number capabilities because it has advanced array/matrix functionalities. Also, most of the machine learning packages do require input as **Numpy** arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrays in Numpy\n",
    "In the code below, we show how **Numpy** arrays work seamlessly with pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Series to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = df.lat.values\n",
    "type(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for i in range(5, 3, 15):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Numpy\n",
    "import numpy as np\n",
    "\n",
    "# create two arrays\n",
    "x = np.array([i + 100 for i in range(10)])\n",
    "y = np.array([i -10 for i in range(10)])\n",
    "\n",
    "# create a dictionary with key as column name and value as the numpy arrays\n",
    "data = {\"x\": x, \"y\":y}\n",
    "\n",
    "# Use the dictinary to create a pandas dataframe\n",
    "df_from_np = pd.DataFrame(data)\n",
    "\n",
    "# Check out the dataframe\n",
    "df_from_np.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array([1,2,3])\n",
    "np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([i + 100 for i in range(10)])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_column_headers = pd.read_csv(data_file, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_column_headers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_column_headers.columns.names = ['psu', 'lon', 'lat', 'str_datetime_sent_hr', 'power_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_column_headers.rename(columns={0:\"psu\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out Numpy Documentation for Additional Details\n",
    "- Back to [Table of Contents](#Table-of-Contents)\n",
    "\n",
    "[Numpy documentation](https://docs.scipy.org/doc/numpy/user/quickstart.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "326px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
